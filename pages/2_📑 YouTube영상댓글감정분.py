import streamlit as st
from googleapiclient.discovery import build
import urllib.parse as urlparse
import pandas as pd
import altair as alt
import os
import torch
from transformers import pipeline
from googleapiclient.errors import HttpError
import time
import random
import json

@st.cache_resource
def load_sentiment_pipeline():
    device = 0 if torch.cuda.is_available() else -1
    return pipeline(
        "text-classification",
        model="Copycats/koelectra-base-v3-generalized-sentiment-analysis",
        tokenizer="Copycats/koelectra-base-v3-generalized-sentiment-analysis",
        device=device,
        framework="pt"
    )

clf = load_sentiment_pipeline()

def analyze_sentiment(text):
    pred = clf(text)[0]
    prob = pred["score"] * 100
    if pred["label"] == "0" and pred["score"] > 0.9:
        label = "ë¶€ì •"
    elif pred["label"] == "1":
        label = "ê¸ì •"
    else:
        label = "ì¤‘ë¦½"
    return label, prob

##################################
#  Youtube API ê´€ë ¨
##################################
API_key = "AIzaSyBrafWWm7JMMHCSe4SpB6vfqfx4YroAOoM"  # ì‹¤ì œ ê°’ìœ¼ë¡œ êµì²´
youtube = build("youtube", "v3", developerKey=API_key)

def get_video_id_from_url(url: str):
    parsed_url = urlparse.urlparse(url)
    query_dict = urlparse.parse_qs(parsed_url.query)
    video_id_list = query_dict.get("v")
    if video_id_list and len(video_id_list) > 0:
        return video_id_list[0]
    return None

def get_comments_by_video_id(video_id, max_results=50):
    comments = []
    page_token = None
    while True:
        # Build request parameters
        params = {
            "part": "snippet,replies",
            "videoId": video_id,
            "maxResults": max_results,
            "textFormat": "plainText",
            "order": "time"
        }
        if page_token:
            params["pageToken"] = page_token

        # Retry loop for transient errors
        for attempt in range(3):
            try:
                request = youtube.commentThreads().list(**params)
                response = request.execute()
                break
            except HttpError as e:
                # Parse error reason
                try:
                    err = json.loads(e.content.decode())
                    reason = err["error"]["errors"][0].get("reason", "")
                except:
                    raise
                if reason == "processingFailure":
                    backoff = (2 ** attempt) + random.random()
                    time.sleep(backoff)
                    continue
                else:
                    raise
        else:
            raise RuntimeError("ëŒ“ê¸€ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë°˜ë³µ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

        # Extract comments
        for item in response.get("items", []):
            top_comment = item["snippet"]["topLevelComment"]["snippet"]["textDisplay"]
            comments.append(top_comment)
            if "replies" in item:
                for reply_item in item["replies"]["comments"]:
                    comments.append(reply_item["snippet"]["textDisplay"])

        # Next page or break
        page_token = response.get("nextPageToken")
        if not page_token:
            break

    return comments

def run_youtube_analysis():
    st.title("ğŸ“‘ ìœ íŠœë¸Œ ì˜ìƒ ëŒ“ê¸€ ê°ì • ë¶„ì„")

    # ì‚¬ìš©ë°©ë²• ì„¤ëª…í•˜ëŠ” ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.subheader("ì‚¬ìš© ë°©ë²•")
        sidebar_url = st.text_area("", value="ì—¬ê¸°ì— ìœ íŠœë¸Œ urlì„ ì…ë ¥í•˜ì„¸ìš”!")

        # ë¶„ì„í•˜ê¸° ë²„íŠ¼ & ì˜¤ë¥¸ìª½ì— "ğŸ‘ˆí´ë¦­!"
        col_sb1, col_sb2 = st.columns([3, 1])
        with col_sb1:
            sidebar_btn1 = st.button("'ìœ íŠœë¸Œ ëŒ“ê¸€ ì¶”ì¶œ & ê°ì • ë¶„ì„'")
        with col_sb2:
            st.write("ğŸ‘ˆ í´ë¦­!")

        # ë¶„ì„ ê²°ê³¼
        st.markdown("---")
        st.subheader("ë¶„ì„ ê²°ê³¼ (ì˜ˆì‹œ)")
        st.image("img/page2_result_count.png")
        st.image("img/page2_result_chart.png")
        st.image("img/page2_result_text.png")

        # ì´ˆê¸°í™” ë°©ë²• í‘œì‹œ
        st.markdown("---")
        st.subheader("ë‹¤ì‹œ ì‘ì„±í•˜ê³ ì‹¶ë‹¤ë©´?")
        col_sb3, col_sb4 = st.columns([1, 2])
        with col_sb3:
            sidebar_btn2 = st.button("'ì´ˆê¸°í™”'")
        with col_sb4:
            st.write("ğŸ‘ˆ í´ë¦­!")


    youtube_url = st.text_input("ë¶„ì„í•  YouTube ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: https://www.youtube.com/watch?v=abcd1234)")

    # ë²„íŠ¼ ë ˆì´ì•„ì›ƒ (ë¶„ì„í•˜ê¸° + ì´ˆê¸°í™” ë²„íŠ¼ ë‚˜ë€íˆ)
    col1, col2, col3 = st.columns([3, 3, 1])

    with col1:
        if st.button("ìœ íŠœë¸Œ ëŒ“ê¸€ ì¶”ì¶œ & ê°ì • ë¶„ì„"):
            if not youtube_url.strip():
                st.warning("YouTube ë§í¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                video_id = get_video_id_from_url(youtube_url)
                if not video_id:
                    st.error("ìœ íš¨í•œ ìœ íŠœë¸Œ URLì´ ì•„ë‹™ë‹ˆë‹¤. v= íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.session_state["YouTube_result"] = {
                        "video_id": video_id
                    }
                    st.session_state["youtube_url"] = youtube_url

    with col3:
        if st.button("ì´ˆê¸°í™”"):
            st.session_state["youtube_url"] = ""
            st.session_state.pop("YouTube_result", None)
            st.rerun()

    if "YouTube_result" in st.session_state:
        with st.spinner("ëŒ“ê¸€ì„ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
            result = st.session_state["YouTube_result"]
            video_id = result["video_id"]
            comments = get_comments_by_video_id(video_id, max_results=50)
        
            if len(comments) == 0:
                st.warning("ëŒ“ê¸€ì´ ì—†ê±°ë‚˜, ëŒ“ê¸€ ì„¤ì •ì´ ë¹„í™œì„±í™”ëœ ì˜ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.success(f"ì´ {len(comments)}ê°œì˜ ëŒ“ê¸€ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                
                sentiments_result = []
                with st.spinner("ëŒ“ê¸€ ê°ì • ë¶„ì„ì¤‘..."):
                    for cmt in comments:
                        s_label, s_score = analyze_sentiment(cmt)
                        sentiments_result.append((cmt, s_label, s_score))
                
                # í†µê³„
                total_count = sum(1 for _, label, _ in sentiments_result)
                pos_count = sum(1 for _, label, _ in sentiments_result if label == "ê¸ì •")
                neg_count = sum(1 for _, label, _ in sentiments_result if label == "ë¶€ì •")
                neu_count = sum(1 for _, label, _ in sentiments_result if label == "ì¤‘ë¦½")
                
                st.subheader("ë¶„ì„ ê²°ê³¼")
                st.write(f"***ì´ ëŒ“ê¸€ ìˆ˜: {total_count}ê°œ***")
                st.write(f"- **:blue[ê¸ì •]** ì ì¸ ëŒ“ê¸€: **{pos_count}**ê°œ")
                st.write(f"- **:red[ë¶€ì •]** ì ì¸ ëŒ“ê¸€: **{neg_count}**ê°œ")
                st.write(f"- **ì¤‘ë¦½** ì ì¸ ëŒ“ê¸€: **{neu_count}**ê°œ")

                st.markdown("---")

                st.subheader("ì°¨íŠ¸")
                                
                # ì°¨íŠ¸ ì‹œê°í™”
                df = pd.DataFrame({
                    "Sentiment": ["Positive", "Negative", "Neutral"],
                    "Percent": [
                        float(f"{(pos_count/total_count * 100):.2f}"),
                        float(f"{(neg_count/total_count * 100):.2f}"),
                        float(f"{(neu_count/total_count * 100):.2f}")
                    ]
                })

                chart = (
                    alt.Chart(df)
                    .mark_arc(stroke="black", strokeWidth=2)  # í…Œë‘ë¦¬ë¥¼ ê²€ì •ìƒ‰, ë‘ê»˜ 2ë¡œ ì„¤ì •
                    .encode(
                        theta=alt.Theta(field="Percent", type="quantitative"),
                        color=alt.Color(
                            field="Sentiment",
                            type="nominal",
                            scale=alt.Scale(
                                domain=["Positive", "Negative", "Neutral"],
                                range=["#ADD8E6", "#FFA07A", "gray"]  # ì—°í•œ íŒŒë€ìƒ‰, ì—°í•œ ë¹¨ê°„ìƒ‰, íšŒìƒ‰
                            ),
                            legend=alt.Legend(labelColor="black", titleColor="black")  # ë²”ë¡€ í…ìŠ¤íŠ¸ë¥¼ ì§„í•˜ê²Œ ì„¤ì •
                        ),
                        tooltip=["Sentiment", "Percent"]
                    )
                    .properties(width=400, height=400)
                )

                st.altair_chart(chart, use_container_width=True)
                
                # ì˜ˆì‹œ ëŒ“ê¸€ ì¶œë ¥
                st.write("### ì˜ˆì‹œ ëŒ“ê¸€")
                for i, (comment_text, label, s_score) in enumerate(sentiments_result[:10], start=1):
                    st.write(f"**{i}.** {comment_text}")
                    st.write(f" - ê°ì •: {label}, ì ìˆ˜: {s_score:.2f}%\n")

if __name__ == "__main__":
    run_youtube_analysis()