import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle
from googleapiclient.discovery import build
import urllib.parse as urlparse
import pandas as pd
import altair as alt
import os

# -- ëª¨ë¸, í† í¬ë‚˜ì´ì € ë¡œë“œ (ìºì‹± ê¶Œì¥) --
@st.cache_resource
def load_sentiment_model():
    model_path = os.path.join("models", "sentiment_model.h5")
    return load_model(model_path)

@st.cache_resource
def load_tokenizer():
    tokenizer_path = os.path.join("models", "tokenizer.pkl")
    with open(tokenizer_path, "rb") as file:
        return pickle.load(file)

model = load_sentiment_model()
tokenizer = load_tokenizer()

def analyze_sentiment(text):
    input_seq = tokenizer.texts_to_sequences([text])
    input_padded = pad_sequences(input_seq, maxlen=100)
    prediction = model.predict(input_padded)[0][0]
    
    if prediction > 0.6:
        sentiment = "ê¸ì •"
    elif prediction < 0.4:
        sentiment = "ë¶€ì •"
    else:
        sentiment = "ì¤‘ë¦½"
    
    prediction_percent = prediction * 100
    return sentiment, prediction_percent

##################################
#  Youtube API ê´€ë ¨
##################################
API_key = "AIzaSyBrafWWm7JMMHCSe4SpB6vfqfx4YroAOoM"  # ì‹¤ì œ ê°’ìœ¼ë¡œ êµì²´
youtube = build("youtube", "v3", developerKey=API_key)

def get_video_id_from_url(url: str):
    parsed_url = urlparse.urlparse(url)
    query_dict = urlparse.parse_qs(parsed_url.query)
    video_id_list = query_dict.get("v")
    if video_id_list and len(video_id_list) > 0:
        return video_id_list[0]
    return None

def get_comments_by_video_id(video_id, max_results=50):
    request = youtube.commentThreads().list(
        part="snippet,replies",
        videoId=video_id,
        maxResults=max_results,
        textFormat="plainText",
        order="time"
    )
    response = request.execute()
    comments = []
    
    while True:
        for item in response.get("items", []):
            # ìƒìœ„ ëŒ“ê¸€
            top_comment = item["snippet"]["topLevelComment"]["snippet"]["textDisplay"]
            comments.append(top_comment)
            
            # ëŒ€ëŒ“ê¸€
            if "replies" in item:
                for reply_item in item["replies"]["comments"]:
                    reply_comment = reply_item["snippet"]["textDisplay"]
                    comments.append(reply_comment)
        
        if "nextPageToken" in response:
            next_page_token = response["nextPageToken"]
            request = youtube.commentThreads().list(
                part="snippet,replies",
                videoId=video_id,
                maxResults=max_results,
                pageToken=next_page_token,
                textFormat="plainText",
                order="time"
            )
            response = request.execute()
        else:
            break
    
    return comments

def run_youtube_analysis():
    st.title("ğŸ“‘ ìœ íŠœë¸Œ ì˜ìƒ ëŒ“ê¸€ ê°ì • ë¶„ì„")

    # ì‚¬ìš©ë°©ë²• ì„¤ëª…í•˜ëŠ” ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.subheader("ì‚¬ìš© ë°©ë²•")
        sidebar_url = st.text_area("", value="ì—¬ê¸°ì— ìœ íŠœë¸Œ urlì„ ì…ë ¥í•˜ì„¸ìš”!")

        # ë¶„ì„í•˜ê¸° ë²„íŠ¼ & ì˜¤ë¥¸ìª½ì— "ğŸ‘ˆí´ë¦­!"
        col_sb1, col_sb2 = st.columns([3, 1])
        with col_sb1:
            sidebar_btn1 = st.button("'ìœ íŠœë¸Œ ëŒ“ê¸€ ì¶”ì¶œ & ê°ì • ë¶„ì„'")
        with col_sb2:
            st.write("ğŸ‘ˆ í´ë¦­!")

        # ë¶„ì„ ê²°ê³¼
        st.markdown("---")
        st.subheader("ë¶„ì„ ê²°ê³¼ (ì˜ˆì‹œ)")
        st.image("img/page2_result_count.png")
        st.image("img/page2_result_chart.png")
        st.image("img/page2_result_text.png")

        # ì´ˆê¸°í™” ë°©ë²• í‘œì‹œ
        st.markdown("---")
        st.subheader("ë‹¤ì‹œ ì‘ì„±í•˜ê³ ì‹¶ë‹¤ë©´?")
        col_sb3, col_sb4 = st.columns([1, 2])
        with col_sb3:
            sidebar_btn2 = st.button("'ì´ˆê¸°í™”'")
        with col_sb4:
            st.write("ğŸ‘ˆ í´ë¦­!")


    youtube_url = st.text_input("ë¶„ì„í•  YouTube ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: https://www.youtube.com/watch?v=abcd1234)")

    # ë²„íŠ¼ ë ˆì´ì•„ì›ƒ (ë¶„ì„í•˜ê¸° + ì´ˆê¸°í™” ë²„íŠ¼ ë‚˜ë€íˆ)
    col1, col2, col3 = st.columns([3, 3, 1])

    with col1:
        if st.button("ìœ íŠœë¸Œ ëŒ“ê¸€ ì¶”ì¶œ & ê°ì • ë¶„ì„"):
            if not youtube_url.strip():
                st.warning("YouTube ë§í¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                video_id = get_video_id_from_url(youtube_url)
                if not video_id:
                    st.error("ìœ íš¨í•œ ìœ íŠœë¸Œ URLì´ ì•„ë‹™ë‹ˆë‹¤. v= íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.session_state["YouTube_result"] = {
                        "video_id": video_id
                    }
                    st.session_state["youtube_url"] = youtube_url

    with col3:
        if st.button("ì´ˆê¸°í™”"):
            st.session_state["youtube_url"] = ""
            st.session_state.pop("YouTube_result", None)
            st.rerun()

    if "YouTube_result" in st.session_state:
        with st.spinner("ëŒ“ê¸€ì„ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
            result = st.session_state["YouTube_result"]
            video_id = result["video_id"]
            comments = get_comments_by_video_id(video_id, max_results=50)
        
            if len(comments) == 0:
                st.warning("ëŒ“ê¸€ì´ ì—†ê±°ë‚˜, ëŒ“ê¸€ ì„¤ì •ì´ ë¹„í™œì„±í™”ëœ ì˜ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.success(f"ì´ {len(comments)}ê°œì˜ ëŒ“ê¸€ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                
                sentiments_result = []
                with st.spinner("ëŒ“ê¸€ ê°ì • ë¶„ì„ì¤‘..."):
                    for cmt in comments:
                        s_label, s_score = analyze_sentiment(cmt)
                        sentiments_result.append((cmt, s_label, s_score))
                
                # í†µê³„
                total_count = sum(1 for _, label, _ in sentiments_result)
                pos_count = sum(1 for _, label, _ in sentiments_result if label == "ê¸ì •")
                neg_count = sum(1 for _, label, _ in sentiments_result if label == "ë¶€ì •")
                neu_count = sum(1 for _, label, _ in sentiments_result if label == "ì¤‘ë¦½")
                
                st.subheader("ë¶„ì„ ê²°ê³¼")
                st.write(f"***ì´ ëŒ“ê¸€ ìˆ˜: {total_count}ê°œ***")
                st.write(f"- **:blue[ê¸ì •]** ì ì¸ ëŒ“ê¸€: **{pos_count}**ê°œ")
                st.write(f"- **:red[ë¶€ì •]** ì ì¸ ëŒ“ê¸€: **{neg_count}**ê°œ")
                st.write(f"- **ì¤‘ë¦½** ì ì¸ ëŒ“ê¸€: **{neu_count}**ê°œ")

                st.markdown("---")

                st.subheader("ì°¨íŠ¸")
                                
                # ì°¨íŠ¸ ì‹œê°í™”
                df = pd.DataFrame({
                    "Sentiment": ["Positive", "Negative", "Neutral"],
                    "Percent": [
                        float(f"{(pos_count/total_count * 100):.2f}"),
                        float(f"{(neg_count/total_count * 100):.2f}"),
                        float(f"{(neu_count/total_count * 100):.2f}")
                    ]
                })

                chart = (
                    alt.Chart(df)
                    .mark_arc(stroke="black", strokeWidth=2)  # í…Œë‘ë¦¬ë¥¼ ê²€ì •ìƒ‰, ë‘ê»˜ 2ë¡œ ì„¤ì •
                    .encode(
                        theta=alt.Theta(field="Percent", type="quantitative"),
                        color=alt.Color(
                            field="Sentiment",
                            type="nominal",
                            scale=alt.Scale(
                                domain=["Positive", "Negative", "Neutral"],
                                range=["#ADD8E6", "#FFA07A", "gray"]  # ì—°í•œ íŒŒë€ìƒ‰, ì—°í•œ ë¹¨ê°„ìƒ‰, ì—°í•œ íšŒìƒ‰
                            ),
                            legend=alt.Legend(labelColor="black", titleColor="black")  # ë²”ë¡€ í…ìŠ¤íŠ¸ë¥¼ ì§„í•˜ê²Œ ì„¤ì •
                        ),
                        tooltip=["Sentiment", "Percent"]
                    )
                    .properties(width=400, height=400)
                )

                st.altair_chart(chart, use_container_width=True)
                
                # ì˜ˆì‹œ ëŒ“ê¸€ ì¶œë ¥
                st.write("### ì˜ˆì‹œ ëŒ“ê¸€")
                for i, (comment_text, label, s_score) in enumerate(sentiments_result[:10], start=1):
                    st.write(f"**{i}.** {comment_text}")
                    st.write(f" - ê°ì •: {label}, ì ìˆ˜: {s_score:.2f}%\n")

if __name__ == "__main__":
    run_youtube_analysis()